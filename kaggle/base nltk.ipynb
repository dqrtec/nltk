{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/alvations/basic-nlp-with-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus é um \"livro\"\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - Fulton - County - Grand - Jury - said - Friday - an - investigation - of - Atlanta's - recent - primary - election - produced - `` - no - evidence - '' - that - any - irregularities - took - place - . - The - jury - further - said - in - term-end - presentments - that - the - City - Executive - Committee - , - which - had - over-all - charge - of - the - election - , - `` - deserves - the - praise - and - thanks - of - the - City - of - Atlanta - '' - for - the - manner - in - which - the - election - was - conducted - . - The - September-October - term - jury - had - been - charged - by - Fulton - Superior - Court - Judge - "
     ]
    }
   ],
   "source": [
    "# palavras contidas no livro\n",
    "for i in range(80):\n",
    "    print(brown.words()[i], end=\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retornas frases do livro\n",
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ca01', 'ca02', 'ca03', 'ca04', 'ca05', 'ca06', 'ca07', 'ca08', 'ca09', 'ca10', 'ca11', 'ca12', 'ca13', 'ca14', 'ca15', 'ca16', 'ca17', 'ca18', 'ca19', 'ca20', 'ca21', 'ca22', 'ca23', 'ca24', 'ca25', 'ca26', 'ca27', 'ca28', 'ca29', 'ca30', 'ca31', 'ca32', 'ca33', 'ca34', 'ca35', 'ca36', 'ca37', 'ca38', 'ca39', 'ca40', 'ca41', 'ca42', 'ca43', 'ca44', 'cb01', 'cb02', 'cb03', 'cb04', 'cb05', 'cb06', 'cb07', 'cb08', 'cb09', 'cb10', 'cb11', 'cb12', 'cb13', 'cb14', 'cb15', 'cb16', 'cb17', 'cb18', 'cb19', 'cb20', 'cb21', 'cb22', 'cb23', 'cb24', 'cb25', 'cb26', 'cb27', 'cc01', 'cc02', 'cc03', 'cc04', 'cc05', 'cc06', 'cc07', 'cc08', 'cc09', 'cc10', 'cc11', 'cc12', 'cc13', 'cc14', 'cc15', 'cc16', 'cc17', 'cd01', 'cd02', 'cd03', 'cd04', 'cd05', 'cd06', 'cd07', 'cd08', 'cd09', 'cd10', 'cd11', 'cd12']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o livro é composto de recursos, cada um tem um titulo\n",
    "print(brown.fileids()[:100])\n",
    "# pegando por titulo\n",
    "brown.sents(fileids='ca01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
      "\n",
      "\n",
      "\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\n",
      "\n",
      "\n",
      "\tThe/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./np \n"
     ]
    }
   ],
   "source": [
    "# texto em formato bruto e categorizado\n",
    "print(brown.raw('ca01').strip()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tokens</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é possivel pegar todos os tokens das frases e dos texto todo\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texto 1.', 'Texto 2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separa sentencas em um texto\n",
    "sent_tokenize(\"texto 1. Texto 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texto', '1', '.']\n",
      "['Texto', '2']\n"
     ]
    }
   ],
   "source": [
    "# pegando palavras de cada frase\n",
    "for sentenca in sent_tokenize( \"texto 1. Texto 2\" ):\n",
    "    print(word_tokenize(sentenca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texto', '1', '.', 'texto', '2']\n"
     ]
    }
   ],
   "source": [
    "# é uma boa pratica utilizar de palavras em LowCase\n",
    "print(list(map(str.lower, word_tokenize(\"texto 1. Texto 2\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>stopwords</h2>\n",
    "são palavras que não interferem na essencia da palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'estamos',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivéramos',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estávamos',\n",
       " 'estão',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'fui',\n",
       " 'fôramos',\n",
       " 'fôssemos',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'havemos',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houveram',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houvermos',\n",
       " 'houverá',\n",
       " 'houverão',\n",
       " 'houveríamos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvéramos',\n",
       " 'houvéssemos',\n",
       " 'há',\n",
       " 'hão',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'não',\n",
       " 'nós',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'são',\n",
       " 'só',\n",
       " 'também',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivéramos',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'tém',\n",
       " 'tínhamos',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'à',\n",
       " 'às',\n",
       " 'é',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "stopwords_pt = set(stopwords.words('portuguese'))\n",
    "stopwords_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texto', '1', '.', 'texto', '2']\n"
     ]
    }
   ],
   "source": [
    "# removendo stopwords\n",
    "print([word for word in [\"a\",'texto', '1', '.', 'texto', '2'] if word not in stopwords_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From string.punctuation: <class 'str'> !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# tambem é possivel remover pontuações\n",
    "print('From string.punctuation:', type(punctuation), punctuation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
